# Thought2Image-cv-proj
Generate Images from Thoughts

## Environment Setup:
Create and activate conda environment named ```dreamdiffusion``` from the ```environment.yaml```
```sh
conda env create -f environment.yaml
conda activate dreamdiffusion
```

## Download checkpoints

We also checkpoints to run the finetuing and decoding directly.

Project Directory Structure:
```
/pretrains
â”£ ğŸ“‚ models
â”ƒ   â”— ğŸ“œ config.yaml
â”ƒ   â”— ğŸ“œ v1-5-pruned.ckpt

â”£ ğŸ“‚ generation  
â”ƒ   â”— ğŸ“œ checkpoint_best.pth 

â”£ ğŸ“‚ eeg_pretain
â”ƒ   â”— ğŸ“œ checkpoint.pth  (pre-trained EEG encoder)

/datasets
â”£ ğŸ“‚ imageNet_images (subset of Imagenet)

â”—  ğŸ“œ block_splits_by_image_all.pth
â”—  ğŸ“œ block_splits_by_image_single.pth 
â”—  ğŸ“œ eeg_5_95_std.pth  

/code
â”£ ğŸ“‚ sc_mbm
â”ƒ   â”— ğŸ“œ mae_for_eeg.py
â”ƒ   â”— ğŸ“œ trainer.py
â”ƒ   â”— ğŸ“œ utils.py

â”£ ğŸ“‚ dc_ldm
â”ƒ   â”— ğŸ“œ ldm_for_eeg.py
â”ƒ   â”— ğŸ“œ utils.py
â”ƒ   â”£ ğŸ“‚ models
â”ƒ   â”ƒ   â”— (adopted from LDM)
â”ƒ   â”£ ğŸ“‚ modules
â”ƒ   â”ƒ   â”— (adopted from LDM)

â”—  ğŸ“œ stageA1_eeg_pretrain.py   (main script for EEG pre-training)
â”—  ğŸ“œ eeg_ldm.py    (main script for fine-tuning stable diffusion)
â”—  ğŸ“œ gen_eval_eeg.py               (main script for generating images)

â”—  ğŸ“œ dataset.py                (functions for loading datasets)
â”—  ğŸ“œ eval_metrics.py           (functions for evaluation metrics)
â”—  ğŸ“œ config.py                 (configurations for the main scripts)
```
